import numpy as np

import pandas as pd
import xgboost as xgb

from xgboost import XGBRegressor

from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from sklearn.metrics import mean_squared_error

from numpy import (
    mean, absolute
)

import seaborn as sns
import os



def hyperParameterTuning(X_train, y_train):
    param_tuning = {
        'learning_rate': [0.01, 0.1],
        'max_depth': [3, 5, 7, 10],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.5, 0.7],
        'colsample_bytree': [0.5, 0.7],
        'n_estimators' : [100, 200, 500],
    }

    xgb_model = xgb.XGBRegressor()

    gsearch = GridSearchCV(estimator = xgb_model,
                           param_grid = param_tuning,                        
                           cv = 5,
                           n_jobs = -1,
                           verbose = 1)

    gsearch.fit(X_train,y_train)

    return gsearch.best_params_

# read training data, path to current directory and cd to train.csv file

train_data = pd.read_csv('C:\\Users\\njpcb\\Projects\\ece470\\data\\train.csv')



train_data.fillna(0, inplace=True)
print(train_data.shape)



corr = train_data.corr()
ax = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
)
print(ax)
train_col = set(list(train_data.columns))
train_target = train_data['SalePrice'].to_frame()
train_data.drop(columns=['SalePrice'], inplace=True)


data_dtypes = train_data.dtypes.to_frame()  # TODO: convert to apply
data_dtypes.reset_index(inplace=True)
data_dtypes.columns = ['col', 'type']
data_obj = data_dtypes.loc[data_dtypes['type'] == 'object'].copy()
list_obj = list(data_obj.col)

for col in list(train_data.columns):
    if  col in list_obj:
            train_data[col] = pd.Categorical(train_data[col])
            train_data[col] = train_data[col].cat.codes



    # first we test it on the train data, and we split it into testing/training
x, y = train_data, train_target
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)
xgbr = xgb.XGBRegressor(verbosity=1, n_estimators=100, max_depth=5, learning_rate=0.1) 
print(xgbr)
xgbr.fit(x_train, y_train)
train_score = xgbr.score(x_train, y_train)  
test_score = xgbr.score(x_test, y_test)

print("This is the test_score: {}".format(test_score))
print("This is the train_score: {}".format(train_score))

scores_k_val = cross_val_score(xgbr, x, y, cv=10)
mean_scores = mean(absolute(scores_k_val))
print(scores_k_val)

print("this is the mean TRAINING score {}".format(mean_scores))



params = hyperParameterTuning(x_train, y_train)

print(params)